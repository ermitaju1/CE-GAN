{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3298a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BiConvLSTMCell(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, input_dim, hidden_dim, kernel_size, bias):\n",
    "        \"\"\"\n",
    "        Initialize ConvLSTM cell.\n",
    "        Parameters\n",
    "        ----------\n",
    "        input_size: (int, int)\n",
    "            Height and width of input tensor as (height, width).\n",
    "        input_dim: int\n",
    "            Number of channels of input tensor.\n",
    "        hidden_dim: int\n",
    "            Number of channels of hidden state.\n",
    "        kernel_size: (int, int)\n",
    "            Size of the convolutional kernel.\n",
    "        bias: bool\n",
    "            Whether or not to add the bias.\n",
    "        \"\"\"\n",
    "\n",
    "        super(BiConvLSTMCell, self).__init__()\n",
    "\n",
    "        self.height, self.width = input_size\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        self.kernel_size = kernel_size\n",
    "        # NOTE: This keeps height and width the same\n",
    "        self.padding = kernel_size[0] // 2, kernel_size[1] // 2\n",
    "        self.bias = bias\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels=self.input_dim + self.hidden_dim,\n",
    "                              out_channels=4 * self.hidden_dim,\n",
    "                              kernel_size=self.kernel_size,\n",
    "                              padding=self.padding,\n",
    "                              bias=self.bias)\n",
    "\n",
    "        # # TODO: we may want this to be different than the conv we use inside each cell\n",
    "        # self.conv_concat = nn.Conv2d(in_channels=2 * self.hidden_dim, #in_channels=self.input_dim + self.hidden_dim,\n",
    "        #                              out_channels=self.hidden_dim,\n",
    "        #                              kernel_size=self.kernel_size,\n",
    "        #                              padding=self.padding,\n",
    "        #                              bias=self.bias)\n",
    "\n",
    "    def forward(self, input_tensor, cur_state):\n",
    "        #h_cur은 input이 들어가는 line, c_cur은 cell state\n",
    "        h_cur, c_cur = cur_state\n",
    "\n",
    "        combined = torch.cat([input_tensor, h_cur], dim=1)  # concatenate along channel axis\n",
    "        # print(\"input_tensor.shape\", input_tensor.shape)   # (b, 256, 8, 8)\n",
    "        # print(\"h_cur.shape\", h_cur.shape)                 # (b, 512, 8, 8)\n",
    "        # print(\"combined.shape\", combined.shape)           # (b, 768, 8, 8)\n",
    "\n",
    "        combined_conv = self.conv(combined) ##결합한거에 conv를 적용해\n",
    "        cc_i, cc_f, cc_o, cc_g = torch.split(combined_conv, self.hidden_dim, dim=1)\n",
    "        i = torch.sigmoid(cc_i)\n",
    "        f = torch.sigmoid(cc_f)\n",
    "        g = torch.tanh(cc_g)\n",
    "        c_next = f * c_cur + i * g\n",
    "        \n",
    "        o = torch.sigmoid(cc_o)\n",
    "        h_next = o * torch.tanh(c_next)\n",
    "        return h_next, c_next\n",
    "\n",
    "\n",
    "class BiConvLSTM(nn.Module):\n",
    "    def __init__(self, input_size, input_dim, hidden_dim, kernel_size, num_layers, device,\n",
    "                 bias=True, return_all_layers=False):\n",
    "        super(BiConvLSTM, self).__init__()\n",
    "\n",
    "        self._check_kernel_size_consistency(kernel_size)\n",
    "\n",
    "        # Make sure that both `kernel_size` and `hidden_dim` are lists having len == num_layers\n",
    "        kernel_size = self._extend_for_multilayer(kernel_size, num_layers)\n",
    "        hidden_dim = self._extend_for_multilayer(hidden_dim, num_layers) #input: (param, num_layer)\n",
    "        \n",
    "        if not len(kernel_size) == len(hidden_dim) == num_layers:\n",
    "            raise ValueError('Inconsistent list length.')\n",
    "        ## kernel size, hidden dim, num layer랑 다 같은 크기여야해서\n",
    "        \n",
    "        self.height, self.width = input_size\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_size = kernel_size\n",
    "        self.num_layers = num_layers\n",
    "        self.device = device\n",
    "        self.bias = bias\n",
    "        self.return_all_layers = return_all_layers\n",
    "\n",
    "        cell_list = []\n",
    "        for i in range(0, self.num_layers):\n",
    "            cur_input_dim = self.input_dim if i == 0 else self.hidden_dim[i - 1]\n",
    "            cell_list.append(BiConvLSTMCell(input_size=(self.height, self.width),\n",
    "                                            input_dim=cur_input_dim,\n",
    "                                            hidden_dim=self.hidden_dim[i],\n",
    "                                            kernel_size=self.kernel_size[i],\n",
    "                                            bias=self.bias))\n",
    "        self.cell_list = nn.ModuleList(cell_list)\n",
    "\n",
    "    def forward(self, input_tensor):\n",
    "        hidden_state = self._init_hidden(batch_size=input_tensor.size(0), device=self.device)\n",
    "\n",
    "        layer_output_list = []\n",
    "\n",
    "        seq_len = input_tensor.size(1)\n",
    "        cur_layer_input = input_tensor\n",
    "\n",
    "        for layer_idx in range(self.num_layers):\n",
    "            backward_states = []\n",
    "            forward_states = []\n",
    "            output_inner = []\n",
    "\n",
    "            #######이해가 안 됨\n",
    "            #hidden backward, cur backward\n",
    "            hb, cb = hidden_state[layer_idx]\n",
    "            for t in range(seq_len):\n",
    "                hb, cb = self.cell_list[layer_idx](input_tensor=cur_layer_input[:, seq_len - t - 1, :, :, :], cur_state=[hb, cb])\n",
    "                backward_states.append(hb)\n",
    "\n",
    "            hf, cf = hidden_state[layer_idx]\n",
    "            for t in range(seq_len):\n",
    "                hf, cf = self.cell_list[layer_idx](input_tensor=cur_layer_input[:, t, :, :, :], cur_state=[hf, cf])\n",
    "                forward_states.append(hf)\n",
    "           \n",
    "        #    ## conv & concat version.....\n",
    "        #     for t in range(seq_len):\n",
    "        #         h = self.cell_list[layer_idx].conv_concat(torch.cat((forward_states[t], backward_states[seq_len - t - 1]), dim=1))\n",
    "        #         output_inner.append(h)\n",
    "\n",
    "            for t in range(seq_len):\n",
    "                h = forward_states[t] + backward_states[seq_len - t - 1]\n",
    "                output_inner.append(h)\n",
    "\n",
    "            layer_output = torch.stack(output_inner, dim=1)   # 3 * (b, 512, 8, 8) -> (b, 3, 512, 8, 8)\n",
    "            cur_layer_input = layer_output\n",
    "\n",
    "            layer_output_list.append(layer_output)            # (num_layers, b, 3, 512, 8, 8)\n",
    "\n",
    "        if not self.return_all_layers:                        # becasue \"return_all_layers=False\"!!!!!  -> (1, b, 3, 512, 8, 8)\n",
    "            return layer_output_list[-1]\n",
    "\n",
    "        return layer_output_list\n",
    "\n",
    "    def _init_hidden(self, batch_size, device):\n",
    "        init_states = []\n",
    "        for i in range(self.num_layers):\n",
    "            init_states.append((Variable(torch.zeros(batch_size, self.hidden_dim[i], self.height, self.width)).to(device),\n",
    "                                Variable(torch.zeros(batch_size, self.hidden_dim[i], self.height, self.width)).to(device)))\n",
    "        return init_states\n",
    "        ##초기tensor 값을 0로 초기화 하기 위함 \n",
    "    \n",
    "    @staticmethod\n",
    "    def _check_kernel_size_consistency(kernel_size):\n",
    "        if not (isinstance(kernel_size, tuple) or\n",
    "                (isinstance(kernel_size, list) and all([isinstance(elem, tuple) for elem in kernel_size]))):\n",
    "            raise ValueError('`kernel_size` must be tuple or list of tuples')\n",
    "\n",
    "    @staticmethod\n",
    "    def _extend_for_multilayer(param, num_layers):\n",
    "        if not isinstance(param, list):  ##list인지 아닌지 판단\n",
    "            param = [param] * num_layers\n",
    "        return param\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
